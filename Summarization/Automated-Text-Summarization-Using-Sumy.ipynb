{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Automated Text Summarization Using Sumy Library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sumy\n",
      "  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting docopt<0.7,>=0.6.1 (from sumy)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting breadability>=0.1.20 (from sumy)\n",
      "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\amamo\\anaconda3\\lib\\site-packages (from sumy) (2.32.2)\n",
      "Collecting pycountry>=18.2.23 (from sumy)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: nltk>=3.0.2 in c:\\users\\amamo\\anaconda3\\lib\\site-packages (from sumy) (3.8.1)\n",
      "Requirement already satisfied: chardet in c:\\users\\amamo\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
      "Requirement already satisfied: lxml>=2.0 in c:\\users\\amamo\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (5.2.1)\n",
      "Requirement already satisfied: click in c:\\users\\amamo\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\amamo\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\amamo\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\amamo\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (4.66.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amamo\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amamo\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amamo\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amamo\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\amamo\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk>=3.0.2->sumy) (0.4.6)\n",
      "Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.3 MB 1.0 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/6.3 MB 1.0 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/6.3 MB 1.0 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.8/6.3 MB 532.3 kB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 0.8/6.3 MB 532.3 kB/s eta 0:00:11\n",
      "   ------ --------------------------------- 1.0/6.3 MB 546.9 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.0/6.3 MB 546.9 kB/s eta 0:00:10\n",
      "   -------- ------------------------------- 1.3/6.3 MB 573.3 kB/s eta 0:00:09\n",
      "   -------- ------------------------------- 1.3/6.3 MB 573.3 kB/s eta 0:00:09\n",
      "   --------- ------------------------------ 1.6/6.3 MB 599.0 kB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 1.8/6.3 MB 621.2 kB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 1.8/6.3 MB 621.2 kB/s eta 0:00:08\n",
      "   ------------- -------------------------- 2.1/6.3 MB 641.6 kB/s eta 0:00:07\n",
      "   -------------- ------------------------- 2.4/6.3 MB 674.3 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 705.5 kB/s eta 0:00:06\n",
      "   ------------------ --------------------- 2.9/6.3 MB 732.5 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 3.1/6.3 MB 765.7 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 3.4/6.3 MB 783.3 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 3.4/6.3 MB 783.3 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 781.6 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 3.9/6.3 MB 798.9 kB/s eta 0:00:04\n",
      "   -------------------------- ------------- 4.2/6.3 MB 825.0 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 833.5 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 853.9 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 5.0/6.3 MB 870.3 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 5.2/6.3 MB 885.5 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 5.5/6.3 MB 897.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 898.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.3 MB 918.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 923.1 kB/s eta 0:00:00\n",
      "Building wheels for collected packages: breadability, docopt\n",
      "  Building wheel for breadability (setup.py): started\n",
      "  Building wheel for breadability (setup.py): finished with status 'done'\n",
      "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21739 sha256=cb079fd827a96055ace768073c9b9f7bd6ef8f41c3c0a458bab682e80efe61b5\n",
      "  Stored in directory: c:\\users\\amamo\\appdata\\local\\pip\\cache\\wheels\\32\\99\\64\\59305409cacd03aa03e7bddf31a9db34b1fa7033bd41972662\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13775 sha256=69ffc8eb3166bb6b6340a45e6cc6c46f1f88a511c1a2b7bcf05b32964b1a1c2a\n",
      "  Stored in directory: c:\\users\\amamo\\appdata\\local\\pip\\cache\\wheels\\1a\\bf\\a1\\4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "Successfully built breadability docopt\n",
      "Installing collected packages: docopt, pycountry, breadability, sumy\n",
      "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-24.6.1 sumy-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sumy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "import nltk\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.utils import get_stop_words\n",
    "from sumy.summarizers.edmundson import EdmundsonSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\amamo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello', 'this', 'is', 'Analytics', 'Vidhya')\n",
      "('We', 'offer', 'a', 'wide', 'range', 'of', 'articles', 'tutorials', 'and', 'resources', 'on', 'various', 'topics', 'in', 'AI', 'and', 'Data', 'Science')\n",
      "('Our', 'mission', 'is', 'to', 'provide', 'quality', 'education', 'and', 'knowledge', 'sharing', 'to', 'help', 'you', 'excel', 'in', 'your', 'career', 'and', 'academic', 'pursuits')\n",
      "('Whether', 'you', 'a', 'beginner', 'looking', 'to', 'learn', 'the', 'basics', 'of', 'coding', 'or', 'an', 'experienced', 'developer', 'seeking', 'advanced', 'concepts', 'Analytics', 'Vidhya', 'has', 'something', 'for', 'everyone')\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(\"en\")\n",
    "\n",
    "sentences = tokenizer.to_sentences(\"\"\"Hello, this is Analytics Vidhya! We offer a wide \n",
    "range of articles, tutorials, and resources on various topics in AI and Data Science. \n",
    "Our mission is to provide quality education and knowledge sharing to help you excel \n",
    "in your career and academic pursuits. Whether you're a beginner looking to learn \n",
    "the basics of coding or an experienced developer seeking advanced concepts, \n",
    "Analytics Vidhya has something for everyone. \"\"\")\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(tokenizer.to_words(sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build Stemmer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blog\n"
     ]
    }
   ],
   "source": [
    "stemmer = Stemmer(\"en\")\n",
    "stem = stemmer(\"Blogging\")\n",
    "print(stem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Luhn Summarizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Luhn Summarizer is one of the summarization algorithms provided by the Sumy library. This summarizer is based on the concept of frequency analysis, where the importance of a sentence is determined by the frequency of significant words within it. The algorithm identifies words that are most relevant to the topic of the text by filterin gout some common stop words and then ranks sentences. The Luhn Summarizer is effective for extracting key sentences from a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.\n",
      "Colloquially, the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\n"
     ]
    }
   ],
   "source": [
    "def summarize_paragraph(paragraph, sentences_count=2):\n",
    "    parser = PlaintextParser.from_string(paragraph, Tokenizer(\"english\"))\n",
    "\n",
    "    summarizer = LuhnSummarizer(Stemmer(\"english\"))\n",
    "    summarizer.stop_words = get_stop_words(\"english\")\n",
    "\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    paragraph = \"\"\"Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast\n",
    "                   to the natural intelligence displayed by humans and animals. Leading AI textbooks define\n",
    "                   the field as the study of \"intelligent agents\": any device that perceives its environment\n",
    "                   and takes actions that maximize its chance of successfully achieving its goals. Colloquially,\n",
    "                   the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic\n",
    "                   \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\"\"\"\n",
    "\n",
    "    sentences_count = 2\n",
    "    summary = summarize_paragraph(paragraph, sentences_count)\n",
    "\n",
    "    for sentence in summary:\n",
    "        print(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edmundson Summarizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Edmundson Summarizer is another powerful algorithm provided by the Sumy library. Unlike other summarizers that primarily rely on statistical and frequency-based methods, the Edmundson Summarizer allows for a more tailored approach through the use of bonus words, stigma words, and null words. These type of words enable the algorithm to emphasize or de-emphasize those words in the summarized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.\n",
      "Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.\n"
     ]
    }
   ],
   "source": [
    "def summarize_paragraph(paragraph, sentences_count=2, bonus_words=None, stigma_words=None, null_words=None):\n",
    "    parser = PlaintextParser.from_string(paragraph, Tokenizer(\"english\"))\n",
    "\n",
    "    summarizer = EdmundsonSummarizer(Stemmer(\"english\"))\n",
    "    summarizer.stop_words = get_stop_words(\"english\")\n",
    "\n",
    "    if bonus_words:\n",
    "        summarizer.bonus_words = bonus_words\n",
    "    if stigma_words:\n",
    "        summarizer.stigma_words = stigma_words\n",
    "    if null_words:\n",
    "        summarizer.null_words = null_words\n",
    "\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    paragraph = \"\"\"Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast\n",
    "                   to the natural intelligence displayed by humans and animals. Leading AI textbooks define\n",
    "                   the field as the study of \"intelligent agents\": any device that perceives its environment\n",
    "                   and takes actions that maximize its chance of successfully achieving its goals. Colloquially,\n",
    "                   the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic\n",
    "                   \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\"\"\"\n",
    "\n",
    "    sentences_count = 2\n",
    "    bonus_words = [\"intelligence\", \"AI\"]\n",
    "    stigma_words = [\"contrast\"]\n",
    "    null_words = [\"the\", \"of\", \"and\", \"to\", \"in\"]\n",
    "\n",
    "    summary = summarize_paragraph(paragraph, sentences_count, bonus_words, stigma_words, null_words)\n",
    "\n",
    "    for sentence in summary:\n",
    "        print(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSA Summarizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSA summarizer is the best one amognst all because it works by identifying patterns and relationships between texts, rather than soley rely on frequency analysis. This LSA summarizer generates more contextually accurate summaries by understanding the meaning and context of the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.\n",
      "Colloquially, the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\n"
     ]
    }
   ],
   "source": [
    "def summarize_paragraph(paragraph, sentences_count=2):\n",
    "    parser = PlaintextParser.from_string(paragraph, Tokenizer(\"english\"))\n",
    "\n",
    "    summarizer = LsaSummarizer(Stemmer(\"english\"))\n",
    "    summarizer.stop_words = get_stop_words(\"english\")\n",
    "\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    paragraph = \"\"\"Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast\n",
    "                   to the natural intelligence displayed by humans and animals. Leading AI textbooks define\n",
    "                   the field as the study of \"intelligent agents\": any device that perceives its environment\n",
    "                   and takes actions that maximize its chance of successfully achieving its goals. Colloquially,\n",
    "                   the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic\n",
    "                   \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\"\"\"\n",
    "\n",
    "    sentences_count = 2\n",
    "    summary = summarize_paragraph(paragraph, sentences_count)\n",
    "\n",
    "    for sentence in summary:\n",
    "        print(sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
